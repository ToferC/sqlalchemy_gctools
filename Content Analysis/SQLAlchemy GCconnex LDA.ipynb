{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sq\n",
    "import pymysql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "sq.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert_unixtime(stamp):\n",
    "    return dt.datetime.fromtimestamp(\n",
    "        int(stamp)\n",
    "    ).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dept List/Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dept_dict = {}\n",
    "\n",
    "data_path = '/home/toferc/Documents/Data/'\n",
    "output_path = '/home/toferc/Documents/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'csv_keys.csv'), \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        email, acronym = row\n",
    "        dept_dict[email] = acronym\n",
    "\n",
    "dept_dict['cadets.gc.ca'] = 'CADETS'\n",
    "dept_dict['canada.gc.ca'] = 'CANADA'\n",
    "dept_dict['canada.ca'] = 'CANADA'\n",
    "dept_dict['tribunal.gc.ca'] = 'TRIBUNAL'\n",
    "dept_dict['cannor.gc.ca'] = 'CED/DEC'\n",
    "dept_dict['ci-oic.gc.ca'] = 'CI/OIC'\n",
    "dept_dict['ccgs-ngcc.gc.ca'] = 'CCGS/NGCC'\n",
    "dept_dict['god.ccgs-ngcc.gc.ca'] = 'CCGS/NGCC'\n",
    "dept_dict['clo-ocol.gc.ca'] = 'OCOL/CLO'\n",
    "dept_dict['csps.gc.ca'] = 'CSPS/EFPC'\n",
    "dept_dict['interenational.gc.ca'] = 'DFAITD/MAECD'\n",
    "dept_dict['cnb-ncw.gc.ca'] = 'CNB/NCW'\n",
    "dept_dict['ncw-cnb.gc.ca'] = 'CNB/NCW'\n",
    "dept_dict['nfb.gc.ca'] = 'NFB/ONF'\n",
    "dept_dict['nrccan-rncan.gc.ca'] = 'NRCAN/RNCAN'\n",
    "dept_dict['nserc-crsng.gc.ca'] = 'NSERC/CRSNG'\n",
    "dept_dict['pbc-clcc.gc.ca'] = 'PBC/CLCC'\n",
    "dept_dict['pco.bcp.gc.ca'] = 'PCO/BCP'\n",
    "dept_dict['pipsc.ca'] = 'PIPSC/IPFPC'\n",
    "dept_dict['ps.sp.gc.ca'] = 'PS/SP'\n",
    "dept_dict['servicecanada.gc.ca.gc.ca'] = 'HRSDC/RHDSC'\n",
    "dept_dict['fintrac-canafe.gc.ca'] = 'FINTRAC'\n",
    "dept_dict['gmail.com'] = 'GMAIL'\n",
    "dept_dict['tribunbal.gc.ca'] = 'TRIBUNAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_dept(email):\n",
    "    ampersand = email.find('@')\n",
    "    tail = email[ampersand + 1:]\n",
    "    try:\n",
    "        return dept_dict[tail]\n",
    "    except KeyError:\n",
    "        return \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dept_list = []\n",
    "\n",
    "for k, v in dept_dict.items():\n",
    "    dept_list.append(v)\n",
    "\n",
    "dept_list = set(dept_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load CIOC members and FTE counts\n",
    "\n",
    "cioc_depts = pd.read_csv(os.path.join(data_path, 'CIOC_depts_jan_2016.csv'),\n",
    "                        thousands=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cioc_depts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "password = getpass.getpass('Enter Password: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MariahDB = 165\n",
    "# MYSQL = 117\n",
    "\n",
    "db_connection = \"mysql+pymysql://gctoolsdata:{}@192.168.1.99:3306/elgg\".format(\n",
    "    password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = sq.create_engine(db_connection,encoding='latin1', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import and_, or_\n",
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Session.configure(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up mappings\n",
    "\n",
    "Users = Base.classes.elggusers_entity\n",
    "Groups = Base.classes.elgggroups_entity\n",
    "Relationships = Base.classes.elggentity_relationships\n",
    "Entities = Base.classes.elggentities\n",
    "Objects = Base.classes.elggobjects_entity\n",
    "MetaData = Base.classes.elggmetadata\n",
    "MetaStrings = Base.classes.elggmetastrings\n",
    "Annotations = Base.classes.elggannotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guide to Elgg Entities\n",
    "\n",
    "Blogs = Entities(subtype=5)\n",
    "Group_Members = Users(relationship=member)\n",
    "Discussions = Entities(subtype=7)\n",
    "Pages = Entities(subtype=10)\n",
    "Wire = Entities(subtype=17)\n",
    "\n",
    "Content = Entities(subtype) -> entity_guid\n",
    "    Elggmetadata(entity_guid) -> name_id, value_id\n",
    "    Elggmetastrings(name_id OR value_id)\n",
    "    \n",
    "#Comments\n",
    "Blog is container entity - GUID = blog guid\n",
    "\n",
    "Blog guid = 10\n",
    "search container for blog guid, return container guid\n",
    "elggmetadata(container_guid)\n",
    "Elggmetastrings(name_id OR value_id)\n",
    "\n",
    "#Skills\n",
    "user_GUID -> elggmetadata(container_guid) - name_id = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up subtype objects of interest\n",
    "\n",
    "subtypes = {'blogs': 5,\n",
    "            'discussions': 7,\n",
    "            'pages': 10,\n",
    "            'wires': 17,\n",
    "            'files': 1,\n",
    "            'images': 19,\n",
    "            'bookmarks': 8,\n",
    "            'ideas': 42\n",
    "           }\n",
    "\n",
    "subtype_list = \"5 7 10 17 1 19 8 42\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pull Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test for pulling out blog info\n",
    "# Cut out: entity.guid, entity.subtype, user.name, objects.title, \n",
    "\n",
    "blogs = []\n",
    "\n",
    "for entity, objects in session.query(\n",
    "    Entities, Objects).filter(\n",
    "        Entities.subtype == 5,\n",
    "        Objects.guid == Entities.guid):\n",
    "    blogs.append((objects.guid, objects.title, objects.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = []\n",
    "\n",
    "for entity, data, strings in session.query(\n",
    "    Entities, MetaData, MetaStrings).filter(\n",
    "        Entities.subtype == 5,\n",
    "        Entities.guid == MetaData.entity_guid).filter(\n",
    "        or_ (MetaStrings.id == MetaData.value_id,\n",
    "        MetaStrings.id == MetaData.name_id)):\n",
    "    tags.append((entity.guid, data.name_id, data.value_id, strings.id,\n",
    "                 strings.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scripts for sorting tags and linking them to guids\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "tag_dict = defaultdict(list)\n",
    "\n",
    "for data in tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    if name_id == string_id and string == 'tags':\n",
    "        tag_dict.setdefault(guid, []).append(value_id)\n",
    "        \n",
    "strings = {}\n",
    "        \n",
    "for data in tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    strings[string_id] =  string\n",
    "    \n",
    "\n",
    "def replace_string_id(tag_list):\n",
    "    return [strings.get(t).lower() for t in tag_list]\n",
    "\n",
    "final_tags = defaultdict(list)\n",
    "\n",
    "for k, v in tag_dict.items():\n",
    "    final_tags[k] = replace_string_id(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strings = {}\n",
    "        \n",
    "for data in tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    strings[string_id] =  string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_dict[1499271]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def replace_string_id(tag_list):\n",
    "    return [strings.get(t).lower() for t in tag_list]\n",
    "\n",
    "'''for element in tag_dict[1499271]:\n",
    "    print(element)\n",
    "    tag_dict[element] = strings.get(tag)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replace_string_id(tag_dict[1499271])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_tags = defaultdict(list)\n",
    "\n",
    "for k, v in tag_dict.items():\n",
    "    final_tags[k] = replace_string_id(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(final_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the frequency of each tag from our text\n",
    "\n",
    "tag_frequency = defaultdict(int)\n",
    "\n",
    "for item in final_tags:\n",
    "    for tag in final_tags[item]:\n",
    "        tag_frequency[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq = pd.DataFrame.from_dict(tag_frequency, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.columns = ['frequency']\n",
    "tag_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.sort_values(by='frequency', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "tag_freq.head(50).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.to_csv(os.path.join(output_path, 'blog_tags.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a sorted dictionary based on the frequency\n",
    "\n",
    "sorted_tag_freq = OrderedDict(sorted(tag_frequency.items(),\n",
    "                                key=lambda kv: kv[1],\n",
    "                                reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_tag_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blogs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blogs[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pull groups from DB\n",
    "\n",
    "groups = []\n",
    "\n",
    "for group, entity in session.query(\n",
    "    Groups, Entities).filter(\n",
    "        Entities.guid == Groups.guid):\n",
    "    groups.append((group.guid, group.name, group.description,\n",
    "                  entity.owner_guid, convert_unixtime(entity.time_created)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull tags from DB\n",
    "\n",
    "group_tags = []\n",
    "\n",
    "for group, entity, data, strings in session.query(\n",
    "    Groups, Entities, MetaData, MetaStrings).filter(\n",
    "        Groups.guid == Entities.guid,\n",
    "        Entities.guid == MetaData.entity_guid).filter(\n",
    "        or_ (MetaStrings.id == MetaData.value_id,\n",
    "        MetaStrings.id == MetaData.name_id)):\n",
    "    group_tags.append((entity.guid, data.name_id, data.value_id, strings.id,\n",
    "                 strings.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scripts for sorting tags and linking them to guids\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_dict = defaultdict(list)\n",
    "\n",
    "for data in group_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    if name_id == string_id and string == 'interests':\n",
    "        tag_dict.setdefault(guid, []).append(value_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strings = {}\n",
    "        \n",
    "for data in group_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    strings[string_id] =  string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_string_id(tag_list):\n",
    "    return [strings.get(t).lower() for t in tag_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_tags = defaultdict(list)\n",
    "\n",
    "for k, v in tag_dict.items():\n",
    "    final_tags[k] = replace_string_id(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Associate groups and tags\n",
    "\n",
    "class GCconnexGroup(object):\n",
    "    \n",
    "    def __init__(self, name, description, owner, created, tags):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.owner = owner\n",
    "        self.created = created\n",
    "        self.tags = tags\n",
    "    \n",
    "    def info(self):\n",
    "        print('''\n",
    "        Name: {name}\n",
    "        Description: {}\n",
    "        Owner: {}\n",
    "        Date Created: {}\n",
    "        Tags: {}'''.format(self.name, self.description, self.owner,\n",
    "                          self.created, self.tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_info = []\n",
    "\n",
    "for group in groups:\n",
    "    guid, name, description, owner_guid, created = group\n",
    "    name = BeautifulSoup(name, \"lxml\")\n",
    "    description = BeautifulSoup(description, \"lxml\")\n",
    "    tags = final_tags.get(guid, \"None\")\n",
    "    group_info.append([name.text, description.text, owner_guid, created, tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(group_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame(group_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim\n",
    "import bz2\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess, lemmatize\n",
    "from gensim.parsing.preprocessing import STOPWORDS as STOPWORDS\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other method for stopwords - not using here.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# create English stop word list\n",
    "en_stops = set(stopwords.words('english'))\n",
    "fr_stops = set(stopwords.words('french'))\n",
    "\n",
    "public_service_stops = '''public service canada work http \n",
    "https travail gcconnex url'''.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "public_service_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [token for token in gensim.utils.simple_preprocess(text)\n",
    "            if token not in STOPWORDS if token not in fr_stops\n",
    "           if token not in public_service_stops if len(token) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tokenize(blogs[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#meaningful_words = [w for w in tokens if not w in en_stop if not w in fr_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Didn't end up going with this.\n",
    "\n",
    "texts = [p_stemmer.stem(i) for i in meaningful_words]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up loop to do this for all blogs\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "texts = []\n",
    "\n",
    "def blog_to_words(raw_blog):/home/toferc/Documents\n",
    "    clean_blog = BeautifulSoup(raw_blog[2], \"lxml\")\n",
    "    #prep_blog = clean_blog.get_text().lower()\n",
    "    #tokens = tokenizer.tokenize(prep_blog)\n",
    "    #meaningful_words = [w for w in tokens if not w in en_stops \n",
    "                        #if not w in fr_stops]\n",
    "    #text = [p_stemmer.stem(i) for i in meaningful_words]\n",
    "    texts.append(tokenize(clean_blog.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, raw_blog in enumerate(blogs):\n",
    "    blog_to_words(raw_blog)\n",
    "    if (i+1)%500 == 0:\n",
    "        print(\"Converted {} of {} blogs.\".format(i+1, len(blogs)))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Went to bed here\n",
    "texts[9422]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "dictionary = corpora.Dictionary(texts) # could include prune_at=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary.save('gcconnex_blogs_dictionary_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the LDA model for our blog corpus\n",
    "\n",
    "ldamodel = models.ldamulticore.LdaMulticore(corpus, num_topics=30,\n",
    "                                           id2word = dictionary,\n",
    "                                            chunksize=1000,\n",
    "                                            passes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel.print_topics(num_topics=20, num_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consider trying Kaggle.com word2vec tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel.top_topics(corpus, num_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove words that occur less than 5 times and than have less than 3 letters\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 5 if len(token) > 3]\n",
    "         for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the frequency of each token from our text\n",
    "\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a sorted dictionary based on the frequency\n",
    "\n",
    "sorted_freq = OrderedDict(sorted(frequency.items(),\n",
    "                                key=lambda kv: kv[1],\n",
    "                                reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model = models.tfidfmodel.TfidfModel(\n",
    "    corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('blogs.csv', 'w+', encoding='latin-1') as f:\n",
    "    for blog in blogs:\n",
    "        f.write(blog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prep for NLTK analysis\n",
    "\n",
    "full_text = \"\\n\".join(blogs)\n",
    "\n",
    "\n",
    "tokens = word_tokenize(full_text)\n",
    "text = nltk.Text(tokens)\n",
    "sens = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_long(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_trigrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
