{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlalchemy as sq\n",
    "import pymysql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sq.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_unixtime(stamp):\n",
    "    return dt.datetime.fromtimestamp(\n",
    "        int(stamp)\n",
    "    ).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dept List/Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dept_dict = {}\n",
    "\n",
    "data_path = r'/Users/toferc/Documents/Data/'\n",
    "output_path = r'/Users/toferc/Documents/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'csv_keys.csv'), \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        email, acronym = row\n",
    "        dept_dict[email] = acronym\n",
    "\n",
    "dept_dict['cadets.gc.ca'] = 'CADETS'\n",
    "dept_dict['canada.gc.ca'] = 'CANADA'\n",
    "dept_dict['canada.ca'] = 'CANADA'\n",
    "dept_dict['tribunal.gc.ca'] = 'TRIBUNAL'\n",
    "dept_dict['cannor.gc.ca'] = 'CED/DEC'\n",
    "dept_dict['ci-oic.gc.ca'] = 'CI/OIC'\n",
    "dept_dict['ccgs-ngcc.gc.ca'] = 'CCGS/NGCC'\n",
    "dept_dict['god.ccgs-ngcc.gc.ca'] = 'CCGS/NGCC'\n",
    "dept_dict['clo-ocol.gc.ca'] = 'OCOL/CLO'\n",
    "dept_dict['csps.gc.ca'] = 'CSPS/EFPC'\n",
    "dept_dict['interenational.gc.ca'] = 'DFAITD/MAECD'\n",
    "dept_dict['cnb-ncw.gc.ca'] = 'CNB/NCW'\n",
    "dept_dict['ncw-cnb.gc.ca'] = 'CNB/NCW'\n",
    "dept_dict['nfb.gc.ca'] = 'NFB/ONF'\n",
    "dept_dict['nrccan-rncan.gc.ca'] = 'NRCAN/RNCAN'\n",
    "dept_dict['nserc-crsng.gc.ca'] = 'NSERC/CRSNG'\n",
    "dept_dict['pbc-clcc.gc.ca'] = 'PBC/CLCC'\n",
    "dept_dict['pco.bcp.gc.ca'] = 'PCO/BCP'\n",
    "dept_dict['pipsc.ca'] = 'PIPSC/IPFPC'\n",
    "dept_dict['ps.sp.gc.ca'] = 'PS/SP'\n",
    "dept_dict['servicecanada.gc.ca.gc.ca'] = 'HRSDC/RHDSC'\n",
    "dept_dict['fintrac-canafe.gc.ca'] = 'FINTRAC'\n",
    "dept_dict['gmail.com'] = 'GMAIL'\n",
    "dept_dict['tribunbal.gc.ca'] = 'TRIBUNAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_dept(email):\n",
    "    ampersand = email.find('@')\n",
    "    tail = email[ampersand + 1:]\n",
    "    try:\n",
    "        return dept_dict[tail]\n",
    "    except KeyError:\n",
    "        return \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dept_list = []\n",
    "\n",
    "for k, v in dept_dict.items():\n",
    "    dept_list.append(v)\n",
    "\n",
    "dept_list = set(dept_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load CIOC members and FTE counts\n",
    "\n",
    "cioc_depts = pd.read_csv(os.path.join(data_path, 'CIOC_depts_jan_2016.csv'),\n",
    "                        thousands=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cioc_depts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MariahDB = 165\n",
    "# MYSQL = 117\n",
    "\n",
    "db_connection = \"mysql+pymysql://root:{}@192.168.2.117:3306/elgg112A\".format(\n",
    "    password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = sq.create_engine(db_connection,encoding='latin1', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import and_, or_\n",
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Session.configure(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Base = automap_base()\n",
    "\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up mappings\n",
    "\n",
    "Users = Base.classes.elggusers_entity\n",
    "Groups = Base.classes.elgggroups_entity\n",
    "Relationships = Base.classes.elggentity_relationships\n",
    "Entities = Base.classes.elggentities\n",
    "Objects = Base.classes.elggobjects_entity\n",
    "MetaData = Base.classes.elggmetadata\n",
    "MetaStrings = Base.classes.elggmetastrings\n",
    "Annotations = Base.classes.elggannotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guide to Elgg Entities\n",
    "\n",
    "Blogs = Entities(subtype=5)\n",
    "Group_Members = Users(relationship=member)\n",
    "Discussions = Entities(subtype=7)\n",
    "Pages = Entities(subtype=10)\n",
    "Wire = Entities(subtype=17)\n",
    "\n",
    "Content = Entities(subtype) -> entity_guid\n",
    "    Elggmetadata(entity_guid) -> name_id, value_id\n",
    "    Elggmetastrings(name_id OR value_id)\n",
    "    \n",
    "#Comments\n",
    "Blog is container entity - GUID = blog guid\n",
    "\n",
    "Blog guid = 10\n",
    "search container for blog guid, return container guid\n",
    "elggmetadata(container_guid)\n",
    "Elggmetastrings(name_id OR value_id)\n",
    "\n",
    "#Skills\n",
    "user_GUID -> elggmetadata(container_guid) - name_id = 60\n",
    "\n",
    "#Departmentlist = subtype = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up subtype objects of interest\n",
    "\n",
    "subtypes = {'blogs': 5,\n",
    "            'discussions': 7,\n",
    "            'pages': 10,\n",
    "            'wires': 17,\n",
    "            'files': 1,\n",
    "            'images': 19,\n",
    "            'bookmarks': 8,\n",
    "            'ideas': 42\n",
    "           }\n",
    "\n",
    "subtype_list = \"5 7 10 17 1 19 8 42\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Updated to pull from new department binning\n",
    "\n",
    "users = {}\n",
    "\n",
    "for e, u, md, ms in session.query(Entities, Users, MetaData, MetaStrings).filter(\n",
    "    Entities.guid == Users.guid,\n",
    "    Entities.guid == MetaData.entity_guid,\n",
    "    MetaData.value_id == MetaStrings.id,\n",
    "    MetaData.name_id == 8667):\n",
    "    users[e.guid] = (e.guid, u.name,\n",
    "                 find_dept(u.email),\n",
    "                ms.string,\n",
    "                 convert_unixtime(e.time_created),\n",
    "                  convert_unixtime(u.last_login),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfusers = pd.DataFrame.from_dict(users, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfusers.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phac = dfusers.loc[dfusers[3] == \"PHAC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull groups from DB\n",
    "\n",
    "groups = []\n",
    "\n",
    "for group, entity in session.query(\n",
    "    Groups, Entities).filter(\n",
    "        Entities.guid == Groups.guid):\n",
    "    try:\n",
    "        groups.append((group.guid, group.name, \n",
    "                   group.description,\n",
    "                   users[entity.owner_guid][3], # Now getting the department flag from the profile\n",
    "                   convert_unixtime(entity.time_created)))\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull tags from DB\n",
    "\n",
    "group_tags = []\n",
    "\n",
    "for group, entity, data, strings in session.query(\n",
    "    Groups, Entities, MetaData, MetaStrings).filter(\n",
    "        Groups.guid == Entities.guid,\n",
    "        Entities.guid == MetaData.entity_guid).filter(\n",
    "        or_ (MetaStrings.id == MetaData.value_id,\n",
    "        MetaStrings.id == MetaData.name_id)):\n",
    "    group_tags.append((entity.guid, data.name_id, data.value_id, strings.id,\n",
    "                 strings.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camel_case(text):\n",
    "    # convert text to camel case (lower, no spaces)\n",
    "    tokens = text.lower().split()\n",
    "    output = \"_\".join(tokens)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_string_id(tag_list):\n",
    "    return [camel_case(strings.get(t).lower()) for t in tag_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scripts for sorting tags and linking them to guids\n",
    "\n",
    "tag_dict = defaultdict(list)\n",
    "\n",
    "for data in group_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    if name_id == string_id and string == 'interests':\n",
    "        tag_dict.setdefault(guid, []).append(value_id)\n",
    "\n",
    "strings = {}\n",
    "        \n",
    "for data in group_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    strings[string_id] =  string\n",
    "\n",
    "group_tags = defaultdict(list)\n",
    "\n",
    "for k, v in tag_dict.items():\n",
    "    group_tags[k] = replace_string_id(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect groups and tags\n",
    "\n",
    "group_info = []\n",
    "\n",
    "for group in groups:\n",
    "    guid, name, description, department, created = group\n",
    "    name = BeautifulSoup(name, \"lxml\")\n",
    "    description = BeautifulSoup(description, \"lxml\")\n",
    "    tags = group_tags.get(guid, \"None\")\n",
    "    group_info.append([guid, name.text, description.text, department, created, tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame(group_info,\n",
    "                       columns = \"guid name description department created tags\".split())\n",
    "\n",
    "group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_df.to_csv(os.path.join(output_path, \"groups.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Group Discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test for pulling out blog info\n",
    "# Cut out: entity.guid, entity.subtype, user.name, objects.title, \n",
    "\n",
    "discussions = []\n",
    "\n",
    "for entity, objects in session.query(\n",
    "    Entities, Objects).filter(\n",
    "        Entities.subtype == 7,\n",
    "        Objects.guid == Entities.guid):\n",
    "    try:\n",
    "        discussions.append((objects.guid, objects.title, objects.description,\n",
    "                 entity.container_guid, users[entity.owner_guid][3], #Pulling department flag from profile\n",
    "                        entity.owner_guid, convert_unixtime(entity.time_created)))\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discussion_tags = []\n",
    "\n",
    "for entity, data, strings in session.query(\n",
    "    Entities, MetaData, MetaStrings).filter(\n",
    "        Entities.subtype == 7,\n",
    "        Entities.guid == MetaData.entity_guid).filter(\n",
    "        or_ (MetaStrings.id == MetaData.value_id,\n",
    "        MetaStrings.id == MetaData.name_id)):\n",
    "    discussion_tags.append((entity.guid, data.name_id, data.value_id, strings.id,\n",
    "                 strings.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scripts for sorting tags and linking them to guids\n",
    "\n",
    "tag_dict = defaultdict(list)\n",
    "\n",
    "for data in discussion_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    if name_id == string_id and string == 'tags':\n",
    "        tag_dict.setdefault(guid, []).append(value_id)\n",
    "        \n",
    "strings = {}\n",
    "        \n",
    "for data in discussion_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    strings[string_id] =  string\n",
    "\n",
    "d_tags = defaultdict(list)\n",
    "\n",
    "for k, v in tag_dict.items():\n",
    "    d_tags[k] = replace_string_id(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect discussions and tags\n",
    "\n",
    "discussion_info = []\n",
    "\n",
    "for discussion in discussions:\n",
    "    guid, title, description, container_guid, department, owner, created = discussion\n",
    "    title = BeautifulSoup(title, \"lxml\")\n",
    "    description = BeautifulSoup(description, \"lxml\")\n",
    "    tags = d_tags.get(guid, \"None\")\n",
    "    discussion_info.append([guid, title.text, description.text, container_guid, \n",
    "                       department, owner, created, tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discussion_df = pd.DataFrame(discussion_info, columns=\"guid title description container department owner created tags\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discussion_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Memberships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "members = []\n",
    "\n",
    "for r in session.query(Relationships).filter(\n",
    "    Relationships.relationship == 'member'):\n",
    "        members.append((\n",
    "            r.guid_one, r.guid_two, convert_unixtime(r.time_created)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creator_link = []\n",
    "\n",
    "for d in discussion_info:\n",
    "    discussion = d[0]\n",
    "    creator = d[5]\n",
    "    created = d[6]\n",
    "    creator_link.append([creator, discussion, created])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect discussions with groups and graph\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create group nodes\n",
    "\n",
    "for group in group_info:\n",
    "    guid, name, description, owner_guid, created, tags = group\n",
    "    G.add_node(guid, type='group', name=name, department=\"group\",\n",
    "               created=created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create discussion nodes\n",
    "\n",
    "for discussion in discussion_info:\n",
    "    guid, title, description, container_guid, department, owner, created, tags = discussion\n",
    "    G.add_node(guid, type='discussion', title=title, description=description, department=department, created=created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create user nodes\n",
    "\n",
    "for user in users:\n",
    "    guid, name, email_department, department, created, login = users[user]\n",
    "    if department:\n",
    "        pass\n",
    "    else:\n",
    "        department == email_department\n",
    "        \n",
    "    G.add_node(guid, type='user',\n",
    "               #name=name,\n",
    "               department=department, \n",
    "               created=created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create discussion edges\n",
    "\n",
    "for discussion in discussion_info:\n",
    "    guid, title, description, container_guid, departnment, owner, created, tags = discussion\n",
    "    G.add_edge(guid, container_guid, created=created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create membership edges\n",
    "\n",
    "for edge in members:\n",
    "    user, group, connected = edge\n",
    "    \n",
    "    G.add_edge(user, group, date=connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create author edges\n",
    "\n",
    "for edge in creator_link:\n",
    "    user, discussion, created = edge\n",
    "    \n",
    "    G.add_edge(user, discussion, date=created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.write_graphml(G, os.path.join(output_path, 'groups_users_graph_2016_11_21.graphml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tags and frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now with all the tags\n",
    "\n",
    "all_tags = []\n",
    "\n",
    "for entity, data, strings in session.query(\n",
    "    Entities, MetaData, MetaStrings).filter(\n",
    "        Entities.subtype.in_(subtype_list),\n",
    "        Entities.guid == MetaData.entity_guid).filter(\n",
    "        or_ (MetaStrings.id == MetaData.value_id,\n",
    "        MetaStrings.id == MetaData.name_id)):\n",
    "    all_tags.append((entity.guid, data.name_id, data.value_id, strings.id,\n",
    "                 strings.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scripts for sorting tags and linking them to guids\n",
    "\n",
    "tag_dict = defaultdict(list)\n",
    "\n",
    "for data in all_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    if name_id == string_id and string in 'tags interests':\n",
    "        tag_dict.setdefault(guid, []).append(value_id)\n",
    "        \n",
    "strings = {}\n",
    "        \n",
    "for data in all_tags:\n",
    "    guid, name_id, value_id, string_id, string = data\n",
    "    strings[string_id] =  string\n",
    "\n",
    "all_tags_final = defaultdict(list)\n",
    "\n",
    "for k, v in tag_dict.items():\n",
    "    all_tags_final[k] = replace_string_id(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the output map\n",
    "\n",
    "tag_map = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_tags(tags):\n",
    "    tag_links = []\n",
    "    list1, list2 = tags, tags\n",
    "    for t1 in list1:\n",
    "        for t2 in list2:\n",
    "            if t1 != t2 and [t2, t1] not in tag_links:\n",
    "                tag_links.append([t1.strip('#'), t2.strip('#')])\n",
    "    \n",
    "    for link in tag_links:\n",
    "        item1, item2 = link\n",
    "        tag_map['{} {}'.format(item1, item2)] = tag_map.get(\n",
    "            '{} {}'.format(item1, item2), 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in group_tags:\n",
    "    link_tags(group_tags[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in all_tags_final:\n",
    "    link_tags(all_tags_final[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tags_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in tag_map.items():\n",
    "    try:\n",
    "        element_one, element_two = k.split(\" \")\n",
    "        N.add_edge(element_one, element_two, weight=v)\n",
    "    except ValueError:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(N, os.path.join(output_path, 'all_tags_graph_2016_11_10.gexf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stopped playing with the full tag cloud here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the frequency of each tag from our text\n",
    "\n",
    "tag_frequency = defaultdict(int)\n",
    "\n",
    "for item in all_tags_final:\n",
    "    for tag in all_tags_final[item]:\n",
    "        tag_frequency[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq = pd.DataFrame.from_dict(tag_frequency, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.columns = ['frequency']\n",
    "tag_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.sort_values(by='frequency', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "tag_freq.head(20).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_freq.to_csv(os.path.join(output_path, 'group_tags_2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a sorted dictionary based on the frequency\n",
    "\n",
    "sorted_tag_freq = OrderedDict(sorted(tag_frequency.items(),\n",
    "                                key=lambda kv: kv[1],\n",
    "                                reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_tag_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(group_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim\n",
    "import bz2\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess, lemmatize\n",
    "from gensim.parsing.preprocessing import STOPWORDS as STOPWORDS\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other method for stopwords - not using here.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# create English stop word list\n",
    "en_stops = set(stopwords.words('english'))\n",
    "fr_stops = set(stopwords.words('french'))\n",
    "\n",
    "public_service_stops = '''public service canada work http \n",
    "https travail gcconnex url time like plus group groupe forum share community'''.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [token for token in gensim.utils.simple_preprocess(text)\n",
    "            if token not in STOPWORDS if token not in fr_stops\n",
    "           if token not in public_service_stops if len(token) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up loop to do this for all blogs\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "texts = []\n",
    "\n",
    "def description_to_words(raw_group):\n",
    "    clean_description = BeautifulSoup(raw_group[2], \"lxml\")\n",
    "    \n",
    "    #prep_blog = clean_blog.get_text().lower()\n",
    "    #tokens = tokenizer.tokenize(prep_blog)\n",
    "    #meaningful_words = [w for w in tokens if not w in en_stops \n",
    "                        #if not w in fr_stops]\n",
    "    #text = [p_stemmer.stem(i) for i in meaningful_words]\n",
    "    \n",
    "    texts.append(tokenize(clean_description.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_tokens = []\n",
    "\n",
    "for tags in all_tags_final:\n",
    "    tag_tokens.append(all_tags_final.get(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, raw_group in enumerate(groups):\n",
    "    description_to_words(raw_group)\n",
    "    if (i+1)%500 == 0:\n",
    "        print(\"Converted {} of {} groups.\".format(i+1, len(groups)))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Went to bed here\n",
    "texts[3800:3850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "dictionary = corpora.Dictionary(texts) # could include prune_at=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary.save('gcconnex_group_tags_dictionary_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the LDA model for our blog corpus\n",
    "\n",
    "ldamodel = models.ldamulticore.LdaMulticore(corpus, num_topics=50,\n",
    "                                           id2word = dictionary,\n",
    "                                            chunksize=1000,\n",
    "                                            passes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel.print_topics(num_topics=20, num_words=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consider trying Kaggle.com word2vec tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldamodel.top_topics(corpus, num_words=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove words that occur less than 5 times and than have less than 3 letters\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 5 if len(token) > 3]\n",
    "         for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the frequency of each token from our text\n",
    "\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a sorted dictionary based on the frequency\n",
    "\n",
    "sorted_freq = OrderedDict(sorted(frequency.items(),\n",
    "                                key=lambda kv: kv[1],\n",
    "                                reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model = models.tfidfmodel.TfidfModel(\n",
    "    corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('groups.csv', 'w+', encoding='latin-1') as f:\n",
    "    for group in groups:\n",
    "        f.write(group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prep for NLTK analysis\n",
    "\n",
    "full_text = \"\\n\".join(blogs)\n",
    "\n",
    "\n",
    "tokens = word_tokenize(full_text)\n",
    "text = nltk.Text(tokens)\n",
    "sens = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_long(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_trigrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
